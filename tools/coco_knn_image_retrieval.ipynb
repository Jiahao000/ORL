{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "willing-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "from mmcv.runner import load_checkpoint\n",
    "from openselfsup.models import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "welsh-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trans(object):\n",
    "    def __init__(self, cfg):\n",
    "        global_trans_list = [\n",
    "            T.Resize(256),\n",
    "            T.CenterCrop(224)\n",
    "        ]\n",
    "        self.global_transform = T.Compose(global_trans_list)\n",
    "        self.img_transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(**cfg.img_norm_cfg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gorgeous-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward global image for knn retrieval\n",
    "def global_forward(img, model):\n",
    "    x = torch.stack(img).cuda()\n",
    "    with torch.no_grad():\n",
    "        x = model.backbone(x)\n",
    "        feats = model.neck(x)[0]\n",
    "        feats_norm = F.normalize(feats, dim=1)\n",
    "    return feats_norm.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pharmaceutical-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use this part for coco\n",
    "work_dirs = '../work_dirs/selfsup/'\n",
    "global_config = '../configs/selfsup/orl/coco/stage1/r50_bs512_ep800_extract_feature.py'\n",
    "global_checkpoint = work_dirs + 'orl/coco/stage1/r50_bs512_ep800/epoch_800.pth'\n",
    "feat_bank_npy = work_dirs + 'orl/coco/stage1/r50_bs512_ep800_extract_feature/feature_epoch_800.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb8c2dc-ce53-40b7-b109-852d168c7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## use this part for coco+\n",
    "# work_dirs = '../work_dirs/selfsup/'\n",
    "# global_config = '../configs/selfsup/orl/cocoplus/stage1/r50_bs512_ep800_extract_feature.py'\n",
    "# global_checkpoint = work_dirs + 'orl/cocoplus/stage1/r50_bs512_ep800/epoch_800.pth'\n",
    "# feat_bank_npy = work_dirs + 'orl/cocoplus/stage1/r50_bs512_ep800_extract_feature/feature_epoch_800.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "potential-trance",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BYOL(\n",
       "  (online_net): Sequential(\n",
       "    (0): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): NonLinearNeckSimCLR(\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (fc0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "      (bn0): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc1): Linear(in_features=4096, out_features=256, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (target_net): Sequential(\n",
       "    (0): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): NonLinearNeckSimCLR(\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (fc0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "      (bn0): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc1): Linear(in_features=4096, out_features=256, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): NonLinearNeckSimCLR(\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (fc0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "    (bn0): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc1): Linear(in_features=4096, out_features=256, bias=False)\n",
       "  )\n",
       "  (head): LatentPredictHead(\n",
       "    (predictor): NonLinearNeckSimCLR(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (fc0): Linear(in_features=256, out_features=4096, bias=True)\n",
       "      (bn0): SyncBatchNorm(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc1): Linear(in_features=4096, out_features=256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_cfg = mmcv.Config.fromfile(global_config)\n",
    "\n",
    "# build the model and load checkpoint\n",
    "global_model = build_model(global_cfg.model)\n",
    "load_checkpoint(global_model, global_checkpoint, map_location='cpu')\n",
    "global_model = global_model.cuda()\n",
    "global_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4035777c-ff14-46c5-848e-c92a6aabaaee",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing batch: 1\n",
      "[INFO] batch 1 took 10.0100 seconds\n",
      "[INFO] processing batch: 513\n",
      "[INFO] batch 513 took 10.5673 seconds\n",
      "[INFO] processing batch: 1025\n",
      "[INFO] batch 1025 took 10.6541 seconds\n",
      "[INFO] processing batch: 1537\n",
      "[INFO] batch 1537 took 10.0347 seconds\n",
      "[INFO] processing batch: 2049\n",
      "[INFO] batch 2049 took 10.2120 seconds\n",
      "[INFO] processing batch: 2561\n",
      "[INFO] batch 2561 took 9.6567 seconds\n",
      "[INFO] processing batch: 3073\n",
      "[INFO] batch 3073 took 9.6550 seconds\n",
      "[INFO] processing batch: 3585\n",
      "[INFO] batch 3585 took 10.1457 seconds\n",
      "[INFO] processing batch: 4097\n",
      "[INFO] batch 4097 took 9.9481 seconds\n",
      "[INFO] processing batch: 4609\n",
      "[INFO] batch 4609 took 10.0417 seconds\n",
      "[INFO] processing batch: 5121\n",
      "[INFO] batch 5121 took 9.7011 seconds\n",
      "[INFO] processing batch: 5633\n",
      "[INFO] batch 5633 took 9.9319 seconds\n",
      "[INFO] processing batch: 6145\n",
      "[INFO] batch 6145 took 9.7829 seconds\n",
      "[INFO] processing batch: 6657\n",
      "[INFO] batch 6657 took 9.7906 seconds\n",
      "[INFO] processing batch: 7169\n",
      "[INFO] batch 7169 took 10.0660 seconds\n",
      "[INFO] processing batch: 7681\n",
      "[INFO] batch 7681 took 10.1345 seconds\n",
      "[INFO] processing batch: 8193\n",
      "[INFO] batch 8193 took 10.4846 seconds\n",
      "[INFO] processing batch: 8705\n",
      "[INFO] batch 8705 took 10.0984 seconds\n",
      "[INFO] processing batch: 9217\n",
      "[INFO] batch 9217 took 10.1365 seconds\n",
      "[INFO] processing batch: 9729\n",
      "[INFO] batch 9729 took 12.0348 seconds\n",
      "[INFO] processing batch: 10241\n",
      "[INFO] batch 10241 took 13.8638 seconds\n",
      "[INFO] processing batch: 10753\n",
      "[INFO] batch 10753 took 9.7690 seconds\n",
      "[INFO] processing batch: 11265\n",
      "[INFO] batch 11265 took 9.8424 seconds\n",
      "[INFO] processing batch: 11777\n",
      "[INFO] batch 11777 took 9.8721 seconds\n",
      "[INFO] processing batch: 12289\n",
      "[INFO] batch 12289 took 9.7161 seconds\n",
      "[INFO] processing batch: 12801\n",
      "[INFO] batch 12801 took 9.6190 seconds\n",
      "[INFO] processing batch: 13313\n",
      "[INFO] batch 13313 took 9.8921 seconds\n",
      "[INFO] processing batch: 13825\n",
      "[INFO] batch 13825 took 10.1577 seconds\n",
      "[INFO] processing batch: 14337\n",
      "[INFO] batch 14337 took 10.2936 seconds\n",
      "[INFO] processing batch: 14849\n",
      "[INFO] batch 14849 took 9.7061 seconds\n",
      "[INFO] processing batch: 15361\n",
      "[INFO] batch 15361 took 10.1033 seconds\n",
      "[INFO] processing batch: 15873\n",
      "[INFO] batch 15873 took 9.7894 seconds\n",
      "[INFO] processing batch: 16385\n",
      "[INFO] batch 16385 took 9.8737 seconds\n",
      "[INFO] processing batch: 16897\n",
      "[INFO] batch 16897 took 10.0911 seconds\n",
      "[INFO] processing batch: 17409\n",
      "[INFO] batch 17409 took 10.1601 seconds\n",
      "[INFO] processing batch: 17921\n",
      "[INFO] batch 17921 took 9.9095 seconds\n",
      "[INFO] processing batch: 18433\n",
      "[INFO] batch 18433 took 9.6642 seconds\n",
      "[INFO] processing batch: 18945\n",
      "[INFO] batch 18945 took 9.8414 seconds\n",
      "[INFO] processing batch: 19457\n",
      "[INFO] batch 19457 took 9.9870 seconds\n",
      "[INFO] processing batch: 19969\n",
      "[INFO] batch 19969 took 10.0133 seconds\n",
      "[INFO] processing batch: 20481\n",
      "[INFO] batch 20481 took 9.9126 seconds\n",
      "[INFO] processing batch: 20993\n",
      "[INFO] batch 20993 took 10.1424 seconds\n",
      "[INFO] processing batch: 21505\n",
      "[INFO] batch 21505 took 10.0119 seconds\n",
      "[INFO] processing batch: 22017\n",
      "[INFO] batch 22017 took 9.8230 seconds\n",
      "[INFO] processing batch: 22529\n",
      "[INFO] batch 22529 took 10.3216 seconds\n",
      "[INFO] processing batch: 23041\n",
      "[INFO] batch 23041 took 9.9151 seconds\n",
      "[INFO] processing batch: 23553\n",
      "[INFO] batch 23553 took 10.0756 seconds\n",
      "[INFO] processing batch: 24065\n",
      "[INFO] batch 24065 took 9.8051 seconds\n",
      "[INFO] processing batch: 24577\n",
      "[INFO] batch 24577 took 9.9518 seconds\n",
      "[INFO] processing batch: 25089\n",
      "[INFO] batch 25089 took 10.5195 seconds\n",
      "[INFO] processing batch: 25601\n",
      "[INFO] batch 25601 took 10.3929 seconds\n",
      "[INFO] processing batch: 26113\n",
      "[INFO] batch 26113 took 10.5286 seconds\n",
      "[INFO] processing batch: 26625\n",
      "[INFO] batch 26625 took 9.9877 seconds\n",
      "[INFO] processing batch: 27137\n",
      "[INFO] batch 27137 took 10.1622 seconds\n",
      "[INFO] processing batch: 27649\n",
      "[INFO] batch 27649 took 9.9123 seconds\n",
      "[INFO] processing batch: 28161\n",
      "[INFO] batch 28161 took 10.0702 seconds\n",
      "[INFO] processing batch: 28673\n",
      "[INFO] batch 28673 took 9.7617 seconds\n",
      "[INFO] processing batch: 29185\n",
      "[INFO] batch 29185 took 9.8618 seconds\n",
      "[INFO] processing batch: 29697\n",
      "[INFO] batch 29697 took 10.0221 seconds\n",
      "[INFO] processing batch: 30209\n",
      "[INFO] batch 30209 took 9.4729 seconds\n",
      "[INFO] processing batch: 30721\n",
      "[INFO] batch 30721 took 9.7982 seconds\n",
      "[INFO] processing batch: 31233\n",
      "[INFO] batch 31233 took 9.8928 seconds\n",
      "[INFO] processing batch: 31745\n",
      "[INFO] batch 31745 took 9.7264 seconds\n",
      "[INFO] processing batch: 32257\n",
      "[INFO] batch 32257 took 9.7088 seconds\n",
      "[INFO] processing batch: 32769\n",
      "[INFO] batch 32769 took 9.4077 seconds\n",
      "[INFO] processing batch: 33281\n",
      "[INFO] batch 33281 took 10.1768 seconds\n",
      "[INFO] processing batch: 33793\n",
      "[INFO] batch 33793 took 9.8467 seconds\n",
      "[INFO] processing batch: 34305\n",
      "[INFO] batch 34305 took 10.2707 seconds\n",
      "[INFO] processing batch: 34817\n",
      "[INFO] batch 34817 took 10.2911 seconds\n",
      "[INFO] processing batch: 35329\n",
      "[INFO] batch 35329 took 10.1043 seconds\n",
      "[INFO] processing batch: 35841\n",
      "[INFO] batch 35841 took 10.3533 seconds\n",
      "[INFO] processing batch: 36353\n",
      "[INFO] batch 36353 took 10.2939 seconds\n",
      "[INFO] processing batch: 36865\n",
      "[INFO] batch 36865 took 10.2618 seconds\n",
      "[INFO] processing batch: 37377\n",
      "[INFO] batch 37377 took 10.4567 seconds\n",
      "[INFO] processing batch: 37889\n",
      "[INFO] batch 37889 took 10.3756 seconds\n",
      "[INFO] processing batch: 38401\n",
      "[INFO] batch 38401 took 10.4066 seconds\n",
      "[INFO] processing batch: 38913\n",
      "[INFO] batch 38913 took 10.8138 seconds\n",
      "[INFO] processing batch: 39425\n",
      "[INFO] batch 39425 took 10.2359 seconds\n",
      "[INFO] processing batch: 39937\n",
      "[INFO] batch 39937 took 13.6385 seconds\n",
      "[INFO] processing batch: 40449\n",
      "[INFO] batch 40449 took 14.3863 seconds\n",
      "[INFO] processing batch: 40961\n",
      "[INFO] batch 40961 took 9.5063 seconds\n",
      "[INFO] processing batch: 41473\n",
      "[INFO] batch 41473 took 9.6055 seconds\n",
      "[INFO] processing batch: 41985\n",
      "[INFO] batch 41985 took 9.7461 seconds\n",
      "[INFO] processing batch: 42497\n",
      "[INFO] batch 42497 took 10.0413 seconds\n",
      "[INFO] processing batch: 43009\n",
      "[INFO] batch 43009 took 10.1420 seconds\n",
      "[INFO] processing batch: 43521\n",
      "[INFO] batch 43521 took 9.8290 seconds\n",
      "[INFO] processing batch: 44033\n",
      "[INFO] batch 44033 took 9.8274 seconds\n",
      "[INFO] processing batch: 44545\n",
      "[INFO] batch 44545 took 9.6909 seconds\n",
      "[INFO] processing batch: 45057\n",
      "[INFO] batch 45057 took 9.7165 seconds\n",
      "[INFO] processing batch: 45569\n",
      "[INFO] batch 45569 took 9.8676 seconds\n",
      "[INFO] processing batch: 46081\n",
      "[INFO] batch 46081 took 10.0133 seconds\n",
      "[INFO] processing batch: 46593\n",
      "[INFO] batch 46593 took 9.9568 seconds\n",
      "[INFO] processing batch: 47105\n",
      "[INFO] batch 47105 took 10.7180 seconds\n",
      "[INFO] processing batch: 47617\n",
      "[INFO] batch 47617 took 10.6679 seconds\n",
      "[INFO] processing batch: 48129\n",
      "[INFO] batch 48129 took 10.2191 seconds\n",
      "[INFO] processing batch: 48641\n",
      "[INFO] batch 48641 took 10.2263 seconds\n",
      "[INFO] processing batch: 49153\n",
      "[INFO] batch 49153 took 9.9189 seconds\n",
      "[INFO] processing batch: 49665\n",
      "[INFO] batch 49665 took 9.6763 seconds\n",
      "[INFO] processing batch: 50177\n",
      "[INFO] batch 50177 took 9.7647 seconds\n",
      "[INFO] processing batch: 50689\n",
      "[INFO] batch 50689 took 9.7217 seconds\n",
      "[INFO] processing batch: 51201\n",
      "[INFO] batch 51201 took 9.4582 seconds\n",
      "[INFO] processing batch: 51713\n",
      "[INFO] batch 51713 took 9.9000 seconds\n",
      "[INFO] processing batch: 52225\n",
      "[INFO] batch 52225 took 9.7365 seconds\n",
      "[INFO] processing batch: 52737\n",
      "[INFO] batch 52737 took 9.8634 seconds\n",
      "[INFO] processing batch: 53249\n",
      "[INFO] batch 53249 took 9.7872 seconds\n",
      "[INFO] processing batch: 53761\n",
      "[INFO] batch 53761 took 9.8390 seconds\n",
      "[INFO] processing batch: 54273\n",
      "[INFO] batch 54273 took 9.9546 seconds\n",
      "[INFO] processing batch: 54785\n",
      "[INFO] batch 54785 took 10.4407 seconds\n",
      "[INFO] processing batch: 55297\n",
      "[INFO] batch 55297 took 10.2034 seconds\n",
      "[INFO] processing batch: 55809\n",
      "[INFO] batch 55809 took 10.2609 seconds\n",
      "[INFO] processing batch: 56321\n",
      "[INFO] batch 56321 took 10.2413 seconds\n",
      "[INFO] processing batch: 56833\n",
      "[INFO] batch 56833 took 9.7625 seconds\n",
      "[INFO] processing batch: 57345\n",
      "[INFO] batch 57345 took 9.6839 seconds\n",
      "[INFO] processing batch: 57857\n",
      "[INFO] batch 57857 took 9.9736 seconds\n",
      "[INFO] processing batch: 58369\n",
      "[INFO] batch 58369 took 10.2613 seconds\n",
      "[INFO] processing batch: 58881\n",
      "[INFO] batch 58881 took 10.0970 seconds\n",
      "[INFO] processing batch: 59393\n",
      "[INFO] batch 59393 took 10.1841 seconds\n",
      "[INFO] processing batch: 59905\n",
      "[INFO] batch 59905 took 10.4567 seconds\n",
      "[INFO] processing batch: 60417\n",
      "[INFO] batch 60417 took 10.4198 seconds\n",
      "[INFO] processing batch: 60929\n",
      "[INFO] batch 60929 took 10.5940 seconds\n",
      "[INFO] processing batch: 61441\n",
      "[INFO] batch 61441 took 9.9943 seconds\n",
      "[INFO] processing batch: 61953\n",
      "[INFO] batch 61953 took 10.2246 seconds\n",
      "[INFO] processing batch: 62465\n",
      "[INFO] batch 62465 took 10.1503 seconds\n",
      "[INFO] processing batch: 62977\n",
      "[INFO] batch 62977 took 10.5083 seconds\n",
      "[INFO] processing batch: 63489\n",
      "[INFO] batch 63489 took 10.1617 seconds\n",
      "[INFO] processing batch: 64001\n",
      "[INFO] batch 64001 took 10.1454 seconds\n",
      "[INFO] processing batch: 64513\n",
      "[INFO] batch 64513 took 10.1825 seconds\n",
      "[INFO] processing batch: 65025\n",
      "[INFO] batch 65025 took 10.5886 seconds\n",
      "[INFO] processing batch: 65537\n",
      "[INFO] batch 65537 took 10.0239 seconds\n",
      "[INFO] processing batch: 66049\n",
      "[INFO] batch 66049 took 9.9420 seconds\n",
      "[INFO] processing batch: 66561\n",
      "[INFO] batch 66561 took 9.9592 seconds\n",
      "[INFO] processing batch: 67073\n",
      "[INFO] batch 67073 took 9.8810 seconds\n",
      "[INFO] processing batch: 67585\n",
      "[INFO] batch 67585 took 9.8559 seconds\n",
      "[INFO] processing batch: 68097\n",
      "[INFO] batch 68097 took 9.9589 seconds\n",
      "[INFO] processing batch: 68609\n",
      "[INFO] batch 68609 took 9.6695 seconds\n",
      "[INFO] processing batch: 69121\n",
      "[INFO] batch 69121 took 9.8268 seconds\n",
      "[INFO] processing batch: 69633\n",
      "[INFO] batch 69633 took 9.5934 seconds\n",
      "[INFO] processing batch: 70145\n",
      "[INFO] batch 70145 took 13.5912 seconds\n",
      "[INFO] processing batch: 70657\n",
      "[INFO] batch 70657 took 13.7946 seconds\n",
      "[INFO] processing batch: 71169\n",
      "[INFO] batch 71169 took 9.1463 seconds\n",
      "[INFO] processing batch: 71681\n",
      "[INFO] batch 71681 took 9.9289 seconds\n",
      "[INFO] processing batch: 72193\n",
      "[INFO] batch 72193 took 9.4911 seconds\n",
      "[INFO] processing batch: 72705\n",
      "[INFO] batch 72705 took 10.1812 seconds\n",
      "[INFO] processing batch: 73217\n",
      "[INFO] batch 73217 took 9.4948 seconds\n",
      "[INFO] processing batch: 73729\n",
      "[INFO] batch 73729 took 9.8749 seconds\n",
      "[INFO] processing batch: 74241\n",
      "[INFO] batch 74241 took 9.4615 seconds\n",
      "[INFO] processing batch: 74753\n",
      "[INFO] batch 74753 took 9.7229 seconds\n",
      "[INFO] processing batch: 75265\n",
      "[INFO] batch 75265 took 9.7695 seconds\n",
      "[INFO] processing batch: 75777\n",
      "[INFO] batch 75777 took 10.2151 seconds\n",
      "[INFO] processing batch: 76289\n",
      "[INFO] batch 76289 took 9.7189 seconds\n",
      "[INFO] processing batch: 76801\n",
      "[INFO] batch 76801 took 9.8247 seconds\n",
      "[INFO] processing batch: 77313\n",
      "[INFO] batch 77313 took 9.7450 seconds\n",
      "[INFO] processing batch: 77825\n",
      "[INFO] batch 77825 took 10.0249 seconds\n",
      "[INFO] processing batch: 78337\n",
      "[INFO] batch 78337 took 9.7098 seconds\n",
      "[INFO] processing batch: 78849\n",
      "[INFO] batch 78849 took 9.5686 seconds\n",
      "[INFO] processing batch: 79361\n",
      "[INFO] batch 79361 took 9.5347 seconds\n",
      "[INFO] processing batch: 79873\n",
      "[INFO] batch 79873 took 9.9682 seconds\n",
      "[INFO] processing batch: 80385\n",
      "[INFO] batch 80385 took 9.6856 seconds\n",
      "[INFO] processing batch: 80897\n",
      "[INFO] batch 80897 took 9.9281 seconds\n",
      "[INFO] processing batch: 81409\n",
      "[INFO] batch 81409 took 9.5016 seconds\n",
      "[INFO] processing batch: 81921\n",
      "[INFO] batch 81921 took 9.7858 seconds\n",
      "[INFO] processing batch: 82433\n",
      "[INFO] batch 82433 took 9.8149 seconds\n",
      "[INFO] processing batch: 82945\n",
      "[INFO] batch 82945 took 10.1406 seconds\n",
      "[INFO] processing batch: 83457\n",
      "[INFO] batch 83457 took 9.7573 seconds\n",
      "[INFO] processing batch: 83969\n",
      "[INFO] batch 83969 took 9.7708 seconds\n",
      "[INFO] processing batch: 84481\n",
      "[INFO] batch 84481 took 9.6061 seconds\n",
      "[INFO] processing batch: 84993\n",
      "[INFO] batch 84993 took 10.0173 seconds\n",
      "[INFO] processing batch: 85505\n",
      "[INFO] batch 85505 took 10.0453 seconds\n",
      "[INFO] processing batch: 86017\n",
      "[INFO] batch 86017 took 9.9852 seconds\n",
      "[INFO] processing batch: 86529\n",
      "[INFO] batch 86529 took 9.5412 seconds\n",
      "[INFO] processing batch: 87041\n",
      "[INFO] batch 87041 took 9.8316 seconds\n",
      "[INFO] processing batch: 87553\n",
      "[INFO] batch 87553 took 9.6454 seconds\n",
      "[INFO] processing batch: 88065\n",
      "[INFO] batch 88065 took 10.2228 seconds\n",
      "[INFO] processing batch: 88577\n",
      "[INFO] batch 88577 took 9.8064 seconds\n",
      "[INFO] processing batch: 89089\n",
      "[INFO] batch 89089 took 9.8723 seconds\n",
      "[INFO] processing batch: 89601\n",
      "[INFO] batch 89601 took 9.5458 seconds\n",
      "[INFO] processing batch: 90113\n",
      "[INFO] batch 90113 took 9.6622 seconds\n",
      "[INFO] processing batch: 90625\n",
      "[INFO] batch 90625 took 9.5633 seconds\n",
      "[INFO] processing batch: 91137\n",
      "[INFO] batch 91137 took 10.1142 seconds\n",
      "[INFO] processing batch: 91649\n",
      "[INFO] batch 91649 took 9.7775 seconds\n",
      "[INFO] processing batch: 92161\n",
      "[INFO] batch 92161 took 9.8213 seconds\n",
      "[INFO] processing batch: 92673\n",
      "[INFO] batch 92673 took 9.6159 seconds\n",
      "[INFO] processing batch: 93185\n",
      "[INFO] batch 93185 took 10.0497 seconds\n",
      "[INFO] processing batch: 93697\n",
      "[INFO] batch 93697 took 9.6488 seconds\n",
      "[INFO] processing batch: 94209\n",
      "[INFO] batch 94209 took 9.9620 seconds\n",
      "[INFO] processing batch: 94721\n",
      "[INFO] batch 94721 took 9.3695 seconds\n",
      "[INFO] processing batch: 95233\n",
      "[INFO] batch 95233 took 9.7265 seconds\n",
      "[INFO] processing batch: 95745\n",
      "[INFO] batch 95745 took 9.6033 seconds\n",
      "[INFO] processing batch: 96257\n",
      "[INFO] batch 96257 took 9.9652 seconds\n",
      "[INFO] processing batch: 96769\n",
      "[INFO] batch 96769 took 9.6427 seconds\n",
      "[INFO] processing batch: 97281\n",
      "[INFO] batch 97281 took 9.7597 seconds\n",
      "[INFO] processing batch: 97793\n",
      "[INFO] batch 97793 took 9.5533 seconds\n",
      "[INFO] processing batch: 98305\n",
      "[INFO] batch 98305 took 10.0527 seconds\n",
      "[INFO] processing batch: 98817\n",
      "[INFO] batch 98817 took 10.2500 seconds\n",
      "[INFO] processing batch: 99329\n",
      "[INFO] batch 99329 took 10.1730 seconds\n",
      "[INFO] processing batch: 99841\n",
      "[INFO] batch 99841 took 10.0967 seconds\n",
      "[INFO] processing batch: 100353\n",
      "[INFO] batch 100353 took 10.0001 seconds\n",
      "[INFO] processing batch: 100865\n",
      "[INFO] batch 100865 took 14.0464 seconds\n",
      "[INFO] processing batch: 101377\n",
      "[INFO] batch 101377 took 9.6176 seconds\n",
      "[INFO] processing batch: 101889\n",
      "[INFO] batch 101889 took 12.7610 seconds\n",
      "[INFO] processing batch: 102401\n",
      "[INFO] batch 102401 took 9.7510 seconds\n",
      "[INFO] processing batch: 102913\n",
      "[INFO] batch 102913 took 9.7099 seconds\n",
      "[INFO] processing batch: 103425\n",
      "[INFO] batch 103425 took 9.8110 seconds\n",
      "[INFO] processing batch: 103937\n",
      "[INFO] batch 103937 took 9.7468 seconds\n",
      "[INFO] processing batch: 104449\n",
      "[INFO] batch 104449 took 9.7978 seconds\n",
      "[INFO] processing batch: 104961\n",
      "[INFO] batch 104961 took 9.6144 seconds\n",
      "[INFO] processing batch: 105473\n",
      "[INFO] batch 105473 took 9.7805 seconds\n",
      "[INFO] processing batch: 105985\n",
      "[INFO] batch 105985 took 9.6678 seconds\n",
      "[INFO] processing batch: 106497\n",
      "[INFO] batch 106497 took 9.5037 seconds\n",
      "[INFO] processing batch: 107009\n",
      "[INFO] batch 107009 took 9.8026 seconds\n",
      "[INFO] processing batch: 107521\n",
      "[INFO] batch 107521 took 9.7563 seconds\n",
      "[INFO] processing batch: 108033\n",
      "[INFO] batch 108033 took 9.8856 seconds\n",
      "[INFO] processing batch: 108545\n",
      "[INFO] batch 108545 took 9.7521 seconds\n",
      "[INFO] processing batch: 109057\n",
      "[INFO] batch 109057 took 9.7473 seconds\n",
      "[INFO] processing batch: 109569\n",
      "[INFO] batch 109569 took 9.7574 seconds\n",
      "[INFO] processing batch: 110081\n",
      "[INFO] batch 110081 took 9.7618 seconds\n",
      "[INFO] processing batch: 110593\n",
      "[INFO] batch 110593 took 9.6938 seconds\n",
      "[INFO] processing batch: 111105\n",
      "[INFO] batch 111105 took 9.7545 seconds\n",
      "[INFO] processing batch: 111617\n",
      "[INFO] batch 111617 took 9.8245 seconds\n",
      "[INFO] processing batch: 112129\n",
      "[INFO] batch 112129 took 9.9383 seconds\n",
      "[INFO] processing batch: 112641\n",
      "[INFO] batch 112641 took 9.9539 seconds\n",
      "[INFO] processing batch: 113153\n",
      "[INFO] batch 113153 took 12.8357 seconds\n",
      "[INFO] processing batch: 113665\n",
      "[INFO] batch 113665 took 9.6030 seconds\n",
      "[INFO] processing batch: 114177\n",
      "[INFO] batch 114177 took 9.7482 seconds\n",
      "[INFO] processing batch: 114689\n",
      "[INFO] batch 114689 took 9.6898 seconds\n",
      "[INFO] processing batch: 115201\n",
      "[INFO] batch 115201 took 10.1048 seconds\n",
      "[INFO] processing batch: 115713\n",
      "[INFO] batch 115713 took 10.0386 seconds\n",
      "[INFO] processing batch: 116225\n",
      "[INFO] batch 116225 took 9.8549 seconds\n",
      "[INFO] processing batch: 116737\n",
      "[INFO] batch 116737 took 9.6148 seconds\n",
      "[INFO] processing batch: 117249\n",
      "[INFO] batch 117249 took 9.8443 seconds\n",
      "[INFO] processing batch: 117761\n",
      "[INFO] batch 117761 took 9.8051 seconds\n",
      "[INFO] processing batch: 118273\n",
      "[INFO] batch 118273 took 0.5223 seconds\n"
     ]
    }
   ],
   "source": [
    "## use this part for coco (train2017)\n",
    "# load data\n",
    "train_json = '../data/coco/annotations/instances_train2017.json'\n",
    "train_root = '../data/coco/train2017/'\n",
    "with open(train_json, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "train_fns = [train_root + item['file_name'] for item in data['images']]\n",
    "imgids = [item['id'] for item in data['images']]\n",
    "knn_imgids = []\n",
    "# batch processing\n",
    "trans = Trans(global_cfg)\n",
    "batch = 512\n",
    "keys = 10\n",
    "feats_bank = torch.from_numpy(np.load(feat_bank_npy)).cuda()\n",
    "for i in range(0, len(train_fns), batch):\n",
    "    print(\"[INFO] processing batch: {}\".format(i + 1))\n",
    "    start = time.time()\n",
    "    if (i + batch) < len(train_fns):\n",
    "        images = [Image.open(fn).convert('RGB') for fn in train_fns[i:i + batch]]\n",
    "    else:\n",
    "        images = [Image.open(fn).convert('RGB') for fn in train_fns[i:len(train_fns)]]\n",
    "    global_images = [trans.global_transform(img) for img in images]\n",
    "    global_tensors = [trans.img_transform(img) for img in global_images]\n",
    "    # retrieve knn images\n",
    "    query_feats = global_forward(global_tensors, global_model)\n",
    "    similarity = torch.mm(query_feats, feats_bank.permute(1, 0))\n",
    "    I = torch.topk(similarity, keys + 1, dim=1)[1].cpu()\n",
    "    I = I[:,1:]  # exclude itself (i.e., 1st nn)\n",
    "    knn_list = I.numpy().tolist()\n",
    "    [knn_imgids.append(knn) for knn in knn_list]\n",
    "    end = time.time()\n",
    "    print(\"[INFO] batch {} took {:.4f} seconds\".format(i + 1, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0d2019-ba9e-4f20-9811-2cbb434b203c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ## use this part for coco+ (train2017+unlabeled2017)\n",
    "# # load data\n",
    "# train_json = '../data/coco/annotations/instances_train2017.json'\n",
    "# unlabeled_json = '../data/coco/annotations/image_info_unlabeled2017.json'\n",
    "# train_root = '../data/cocoplus/trainplus2017/'\n",
    "# with open(train_json, 'r') as f1:\n",
    "#     data = json.load(f1)\n",
    "# with open(unlabeled_json, 'r') as f2:\n",
    "#     unlabeled_data = json.load(f2)\n",
    "# data['images'].extend(unlabeled_data['images'])\n",
    "# train_fns = [train_root + item['file_name'] for item in data['images']]\n",
    "# imgids = [item['id'] for item in data['images']]\n",
    "# knn_imgids = []\n",
    "# # batch processing\n",
    "# trans = Trans(global_cfg)\n",
    "# batch = 512\n",
    "# keys = 10\n",
    "# feats_bank = torch.from_numpy(np.load(feat_bank_npy)).cuda()\n",
    "# for i in range(0, len(train_fns), batch):\n",
    "#     print(\"[INFO] processing batch: {}\".format(i + 1))\n",
    "#     start = time.time()\n",
    "#     if (i + batch) < len(train_fns):\n",
    "#         images = [Image.open(fn).convert('RGB') for fn in train_fns[i:i + batch]]\n",
    "#     else:\n",
    "#         images = [Image.open(fn).convert('RGB') for fn in train_fns[i:len(train_fns)]]\n",
    "#     global_images = [trans.global_transform(img) for img in images]\n",
    "#     global_tensors = [trans.img_transform(img) for img in global_images]\n",
    "#     # retrieve knn images\n",
    "#     query_feats = global_forward(global_tensors, global_model)\n",
    "#     similarity = torch.mm(query_feats, feats_bank.permute(1, 0))\n",
    "#     I = torch.topk(similarity, keys + 1, dim=1)[1].cpu()\n",
    "#     I = I[:,1:]  # exclude itself (i.e., 1st nn)\n",
    "#     knn_list = I.numpy().tolist()\n",
    "#     [knn_imgids.append(knn) for knn in knn_list]\n",
    "#     end = time.time()\n",
    "#     print(\"[INFO] batch {} took {:.4f} seconds\".format(i + 1, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "approximate-native",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] image-level knn json file has been saved to ../data/coco/meta/train2017_10nn_instance.json\n"
     ]
    }
   ],
   "source": [
    "# save image id and knn image id as a json file\n",
    "data_new = {}\n",
    "num_image = 118287  # 118287 for coco, 241690 for coco+ \n",
    "save_path = '../data/coco/meta/train2017_{}nn_instance.json'.format(keys)\n",
    "# save_path = '../data/cocoplus/meta/trainplus2017_{}nn_instance.json'.format(keys)\n",
    "assert len(imgids) == len(knn_imgids) == len(train_fns) == num_image, \\\n",
    "    \"Mismatch the total number of images in training set, got: {}\".format(len(knn_imgids))\n",
    "# dict\n",
    "info = {}\n",
    "image_info = {}\n",
    "pseudo_anno = {}\n",
    "info['knn_image_num'] = keys\n",
    "image_info['file_name'] = [item['file_name'] for item in data['images']]\n",
    "image_info['id'] = [item['id'] for item in data['images']]\n",
    "pseudo_anno['image_id'] = imgids\n",
    "pseudo_anno['knn_image_id'] = knn_imgids\n",
    "data_new['info'] = info\n",
    "data_new['images'] = image_info\n",
    "data_new['pseudo_annotations'] = pseudo_anno\n",
    "with open(save_path, 'w') as f:\n",
    "    json.dump(data_new, f)\n",
    "print(\"[INFO] image-level knn json file has been saved to {}\".format(save_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
